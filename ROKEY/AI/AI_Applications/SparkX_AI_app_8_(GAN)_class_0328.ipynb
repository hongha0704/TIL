{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyOUfIttqzmK9s8t1hoSLELA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CpT2oY5hp5if","executionInfo":{"status":"ok","timestamp":1743147935307,"user_tz":-540,"elapsed":9,"user":{"displayName":"백홍하","userId":"05665897588922241265"}},"outputId":"9c6048a2-3c44-4664-8281-2e24501ad0de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":1}],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch import nn, optim\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","source":["num_epoch = 1000\n","batch_size = 100\n","lr = 0.0001\n","img_size = 28*28\n","num_channel = 1\n","dir_name = 'GAN_result'\n","\n","## generator parameter\n","noise_size = 100\n","hidden_size1 = 256\n","hidden_size2 = 512\n","\n","##\n","if not os.path.exists(dir_name):\n","  os.makedirs(dir_name)"],"metadata":{"id":"9sTSnAWwuc7v","executionInfo":{"status":"ok","timestamp":1743148644288,"user_tz":-540,"elapsed":41,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(0.5, 0.5)\n","])"],"metadata":{"id":"eUw9K_vdtqVv","executionInfo":{"status":"ok","timestamp":1743148148276,"user_tz":-540,"elapsed":5,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["MNIST_dataset = datasets.MNIST(root='./', train=True, transform=transform, download=True)\n","\n","data_loader = DataLoader(dataset=MNIST_dataset, batch_size=batch_size, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1E0PypUIt-lo","executionInfo":{"status":"ok","timestamp":1743148200702,"user_tz":-540,"elapsed":25951,"user":{"displayName":"백홍하","userId":"05665897588922241265"}},"outputId":"fb076790-9c4a-46e5-b345-348f2a3e08c1"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 9.91M/9.91M [00:11<00:00, 901kB/s] \n","100%|██████████| 28.9k/28.9k [00:00<00:00, 65.6kB/s]\n","100%|██████████| 1.65M/1.65M [00:06<00:00, 245kB/s]\n","100%|██████████| 4.54k/4.54k [00:00<00:00, 8.89MB/s]\n"]}]},{"cell_type":"markdown","source":["# Discriminator"],"metadata":{"id":"i_UxRQF0ylN8"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.linear1 = nn.Linear(img_size, hidden_size2)\n","    self.linear2 = nn.Linear(hidden_size2, hidden_size1)\n","    self.linear3 = nn.Linear(hidden_size1, 1)\n","    self.leaky_relu = nn.LeakyReLU(0.2)\n","    self.sigmoid = nn.Sigmoid()\n","\n","  def forward(self, x):\n","    x = self.leaky_relu(self.linear1(x))\n","    x = self.leaky_relu(self.linear2(x))\n","    x = self.linear3(x)\n","    x = self.sigmoid(x)\n","    return x"],"metadata":{"id":"6D6gzQJLuk0b","executionInfo":{"status":"ok","timestamp":1743149596221,"user_tz":-540,"elapsed":1,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Generator"],"metadata":{"id":"8yD7OhpVymGO"}},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    self.linear1 = nn.Linear(noise_size, hidden_size1)\n","    self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n","    self.linear3 = nn.Linear(hidden_size2, img_size)    ## MNIST\n","    self.relu = nn.ReLU()\n","    self.tanh = nn.Tanh()\n","\n","  def forward(self, x):\n","    x = self.relu(self.linear1(x))\n","    x = self.relu(self.linear2(x))\n","    x = self.linear3(x)\n","    x = self.tanh(x)\n","    return x"],"metadata":{"id":"SVQBMVSXyo39","executionInfo":{"status":"ok","timestamp":1743149551413,"user_tz":-540,"elapsed":5,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["discriminator = Discriminator().to(device)\n","generator = Generator().to(device)"],"metadata":{"id":"e3tCWK_-zzFm","executionInfo":{"status":"ok","timestamp":1743149598975,"user_tz":-540,"elapsed":221,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Vanilla GAN"],"metadata":{"id":"TF6qWh9s0cdi"}},{"cell_type":"code","source":["criterion = nn.BCELoss()\n","d_optimizer = optim.Adam(discriminator.parameters(), lr=lr)\n","g_optimizer = optim.Adam(generator.parameters(), lr=lr)"],"metadata":{"id":"ldK5I3w6z8Jg","executionInfo":{"status":"ok","timestamp":1743149844658,"user_tz":-540,"elapsed":42,"user":{"displayName":"백홍하","userId":"05665897588922241265"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["for epoch in range(num_epoch):\n","  for i, (images, labels) in enumerate(data_loader):\n","    real_label = torch.full((batch_size, 1), 1, dtype=torch.float32).to(device) # 1\n","    fake_label = torch.full((batch_size, 1), 0, dtype=torch.float32).to(device) # 1\n","\n","    real_images = images.view(batch_size, -1).to(device)\n","\n","    ### generator training\n","    g_optimizer.zero_grad()\n","    z = torch.randn(batch_size, noise_size).to(device)\n","    fake_images = generator(z)\n","    g_loss = criterion(discriminator(fake_images), real_label)\n","    g_loss.backward()\n","    g_optimizer.step()\n","\n","    ### discriminator training\n","    z = torch.randn(batch_size, noise_size).to(device)\n","    fake_images = generator(z)\n","\n","    fake_prediction = discriminator(fake_images)\n","    real_prediction = discriminator(real_images)\n","\n","    fake_loss = criterion(fake_prediction, fake_label)\n","    real_loss = criterion(real_prediction, real_label)\n","    d_loss = (fake_loss + real_loss) / 2\n","\n","    d_optimizer.zero_grad()\n","    d_loss.backward()\n","    d_optimizer.step()\n","\n","    if (i+1) % 150 == 0:\n","      print(f'Epoch [{epoch}/{num_epoch}] Step [{i+1}/{len(data_loader)}] d_loss: {d_loss.item()} g_loss: {g_loss.item()}')\n","\n","  samples = fake_images.reshape(batch_size, 1, 28, 28)\n","  save_image(samples, os.path.join(dir_name, f'Gan_fake_samples{epoch+1}.png'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Mqas54EQ08f-","executionInfo":{"status":"error","timestamp":1743152613992,"user_tz":-540,"elapsed":1238978,"user":{"displayName":"백홍하","userId":"05665897588922241265"}},"outputId":"40aa0d67-f29e-4f3a-c404-2d6b75b3e7e8"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [0/1000] Step [150/600] d_loss: 0.15048757195472717 g_loss: 2.387244701385498\n","Epoch [0/1000] Step [300/600] d_loss: 0.04329875484108925 g_loss: 3.500458240509033\n","Epoch [0/1000] Step [450/600] d_loss: 0.1515117883682251 g_loss: 3.5689995288848877\n","Epoch [0/1000] Step [600/600] d_loss: 0.05694755166769028 g_loss: 3.7506794929504395\n","Epoch [1/1000] Step [150/600] d_loss: 0.08705539256334305 g_loss: 3.467283248901367\n","Epoch [1/1000] Step [300/600] d_loss: 0.10833865404129028 g_loss: 3.259143829345703\n","Epoch [1/1000] Step [450/600] d_loss: 0.09509746730327606 g_loss: 3.2585508823394775\n","Epoch [1/1000] Step [600/600] d_loss: 0.07430216670036316 g_loss: 3.7650530338287354\n","Epoch [2/1000] Step [150/600] d_loss: 0.43539804220199585 g_loss: 2.534571886062622\n","Epoch [2/1000] Step [300/600] d_loss: 0.08592623472213745 g_loss: 3.6821696758270264\n","Epoch [2/1000] Step [450/600] d_loss: 0.10013408958911896 g_loss: 3.3634300231933594\n","Epoch [2/1000] Step [600/600] d_loss: 0.4433450400829315 g_loss: 2.799532413482666\n","Epoch [3/1000] Step [150/600] d_loss: 0.3767186403274536 g_loss: 2.010658025741577\n","Epoch [3/1000] Step [300/600] d_loss: 0.1181597113609314 g_loss: 2.8103201389312744\n","Epoch [3/1000] Step [450/600] d_loss: 0.23356425762176514 g_loss: 2.0547330379486084\n","Epoch [3/1000] Step [600/600] d_loss: 0.1380375623703003 g_loss: 2.8037216663360596\n","Epoch [4/1000] Step [150/600] d_loss: 0.09806004911661148 g_loss: 2.675584077835083\n","Epoch [4/1000] Step [300/600] d_loss: 0.11797978729009628 g_loss: 2.876385450363159\n","Epoch [4/1000] Step [450/600] d_loss: 0.1506064236164093 g_loss: 2.788181781768799\n","Epoch [4/1000] Step [600/600] d_loss: 0.0669705718755722 g_loss: 3.579352855682373\n","Epoch [5/1000] Step [150/600] d_loss: 0.0458187609910965 g_loss: 3.9486546516418457\n","Epoch [5/1000] Step [300/600] d_loss: 0.06057753413915634 g_loss: 3.9368693828582764\n","Epoch [5/1000] Step [450/600] d_loss: 0.05709848552942276 g_loss: 3.5166842937469482\n","Epoch [5/1000] Step [600/600] d_loss: 0.04943472892045975 g_loss: 4.149284839630127\n","Epoch [6/1000] Step [150/600] d_loss: 0.019320962950587273 g_loss: 5.844130516052246\n","Epoch [6/1000] Step [300/600] d_loss: 0.017860310152173042 g_loss: 6.203526496887207\n","Epoch [6/1000] Step [450/600] d_loss: 0.05307963490486145 g_loss: 4.858815670013428\n","Epoch [6/1000] Step [600/600] d_loss: 0.03742845356464386 g_loss: 4.833266258239746\n","Epoch [7/1000] Step [150/600] d_loss: 0.02962985262274742 g_loss: 5.466701030731201\n","Epoch [7/1000] Step [300/600] d_loss: 0.010455027222633362 g_loss: 6.940061569213867\n","Epoch [7/1000] Step [450/600] d_loss: 0.019008154049515724 g_loss: 6.589639663696289\n","Epoch [7/1000] Step [600/600] d_loss: 0.04758206009864807 g_loss: 4.5323166847229\n","Epoch [8/1000] Step [150/600] d_loss: 0.04792921245098114 g_loss: 4.484347820281982\n","Epoch [8/1000] Step [300/600] d_loss: 0.08677919954061508 g_loss: 3.863704204559326\n","Epoch [8/1000] Step [450/600] d_loss: 0.03132598474621773 g_loss: 8.059301376342773\n","Epoch [8/1000] Step [600/600] d_loss: 0.0201580673456192 g_loss: 6.605750560760498\n","Epoch [9/1000] Step [150/600] d_loss: 0.028526462614536285 g_loss: 5.355701923370361\n","Epoch [9/1000] Step [300/600] d_loss: 0.053353361785411835 g_loss: 4.635782241821289\n","Epoch [9/1000] Step [450/600] d_loss: 0.0565270259976387 g_loss: 4.563540935516357\n","Epoch [9/1000] Step [600/600] d_loss: 0.0477568544447422 g_loss: 4.895422458648682\n","Epoch [10/1000] Step [150/600] d_loss: 0.03152724727988243 g_loss: 4.762856483459473\n","Epoch [10/1000] Step [300/600] d_loss: 0.09260908514261246 g_loss: 6.999947547912598\n","Epoch [10/1000] Step [450/600] d_loss: 0.0621873140335083 g_loss: 5.267539024353027\n","Epoch [10/1000] Step [600/600] d_loss: 0.03642161935567856 g_loss: 5.093039512634277\n","Epoch [11/1000] Step [150/600] d_loss: 0.06020418927073479 g_loss: 4.236880302429199\n","Epoch [11/1000] Step [300/600] d_loss: 0.06876610964536667 g_loss: 4.102344989776611\n","Epoch [11/1000] Step [450/600] d_loss: 0.09541112184524536 g_loss: 3.8977413177490234\n","Epoch [11/1000] Step [600/600] d_loss: 0.09749066829681396 g_loss: 4.076601982116699\n","Epoch [12/1000] Step [150/600] d_loss: 0.025035344064235687 g_loss: 5.333992004394531\n","Epoch [12/1000] Step [300/600] d_loss: 0.031963709741830826 g_loss: 6.000630855560303\n","Epoch [12/1000] Step [450/600] d_loss: 0.09671677649021149 g_loss: 6.416422367095947\n","Epoch [12/1000] Step [600/600] d_loss: 0.030561933293938637 g_loss: 5.854147434234619\n","Epoch [13/1000] Step [150/600] d_loss: 0.0754779577255249 g_loss: 5.3787689208984375\n","Epoch [13/1000] Step [300/600] d_loss: 0.082170769572258 g_loss: 6.142720699310303\n","Epoch [13/1000] Step [450/600] d_loss: 0.08261299878358841 g_loss: 4.924195766448975\n","Epoch [13/1000] Step [600/600] d_loss: 0.06962628662586212 g_loss: 5.515617370605469\n","Epoch [14/1000] Step [150/600] d_loss: 0.02613474614918232 g_loss: 5.185222625732422\n","Epoch [14/1000] Step [300/600] d_loss: 0.0988474041223526 g_loss: 3.553016185760498\n","Epoch [14/1000] Step [450/600] d_loss: 0.07744774222373962 g_loss: 3.9366021156311035\n","Epoch [14/1000] Step [600/600] d_loss: 0.08739077299833298 g_loss: 4.239015579223633\n","Epoch [15/1000] Step [150/600] d_loss: 0.13265666365623474 g_loss: 7.664399147033691\n","Epoch [15/1000] Step [300/600] d_loss: 0.09350739419460297 g_loss: 3.984405517578125\n","Epoch [15/1000] Step [450/600] d_loss: 0.06593998521566391 g_loss: 3.889463424682617\n","Epoch [15/1000] Step [600/600] d_loss: 0.037654511630535126 g_loss: 5.14188814163208\n","Epoch [16/1000] Step [150/600] d_loss: 0.06628119945526123 g_loss: 7.2558274269104\n","Epoch [16/1000] Step [300/600] d_loss: 0.07125494629144669 g_loss: 5.774621963500977\n","Epoch [16/1000] Step [450/600] d_loss: 0.07487088441848755 g_loss: 4.762293815612793\n","Epoch [16/1000] Step [600/600] d_loss: 0.1632426232099533 g_loss: 6.433117389678955\n","Epoch [17/1000] Step [150/600] d_loss: 0.08684922754764557 g_loss: 6.243136405944824\n","Epoch [17/1000] Step [300/600] d_loss: 0.07057667523622513 g_loss: 3.786487340927124\n","Epoch [17/1000] Step [450/600] d_loss: 0.043973952531814575 g_loss: 4.944193363189697\n","Epoch [17/1000] Step [600/600] d_loss: 0.06875234097242355 g_loss: 6.022348403930664\n","Epoch [18/1000] Step [150/600] d_loss: 0.02400212734937668 g_loss: 5.308711528778076\n","Epoch [18/1000] Step [300/600] d_loss: 0.042516693472862244 g_loss: 6.138588905334473\n","Epoch [18/1000] Step [450/600] d_loss: 0.07685030251741409 g_loss: 5.385078430175781\n","Epoch [18/1000] Step [600/600] d_loss: 0.11240308731794357 g_loss: 6.095439910888672\n","Epoch [19/1000] Step [150/600] d_loss: 0.04905545711517334 g_loss: 7.361501693725586\n","Epoch [19/1000] Step [300/600] d_loss: 0.0459064319729805 g_loss: 5.01582145690918\n","Epoch [19/1000] Step [450/600] d_loss: 0.062420476227998734 g_loss: 5.979122638702393\n","Epoch [19/1000] Step [600/600] d_loss: 0.020317668095231056 g_loss: 6.202826023101807\n","Epoch [20/1000] Step [150/600] d_loss: 0.040864862501621246 g_loss: 5.540676116943359\n","Epoch [20/1000] Step [300/600] d_loss: 0.10101983696222305 g_loss: 7.532212734222412\n","Epoch [20/1000] Step [450/600] d_loss: 0.04159851744771004 g_loss: 4.510472774505615\n","Epoch [20/1000] Step [600/600] d_loss: 0.06621401011943817 g_loss: 5.4568681716918945\n","Epoch [21/1000] Step [150/600] d_loss: 0.1428738683462143 g_loss: 3.929720401763916\n","Epoch [21/1000] Step [300/600] d_loss: 0.11497930437326431 g_loss: 6.216712951660156\n","Epoch [21/1000] Step [450/600] d_loss: 0.03814465180039406 g_loss: 5.503182411193848\n","Epoch [21/1000] Step [600/600] d_loss: 0.13440252840518951 g_loss: 5.945600509643555\n","Epoch [22/1000] Step [150/600] d_loss: 0.1520879566669464 g_loss: 3.154057025909424\n","Epoch [22/1000] Step [300/600] d_loss: 0.15894865989685059 g_loss: 6.731721878051758\n","Epoch [22/1000] Step [450/600] d_loss: 0.052606113255023956 g_loss: 6.444231986999512\n","Epoch [22/1000] Step [600/600] d_loss: 0.06242147833108902 g_loss: 5.658295631408691\n","Epoch [23/1000] Step [150/600] d_loss: 0.05474386364221573 g_loss: 4.848121166229248\n","Epoch [23/1000] Step [300/600] d_loss: 0.09444351494312286 g_loss: 4.646798133850098\n","Epoch [23/1000] Step [450/600] d_loss: 0.06852610409259796 g_loss: 4.800609111785889\n","Epoch [23/1000] Step [600/600] d_loss: 0.07415834069252014 g_loss: 4.846731662750244\n","Epoch [24/1000] Step [150/600] d_loss: 0.05196622014045715 g_loss: 4.450871467590332\n","Epoch [24/1000] Step [300/600] d_loss: 0.06318885833024979 g_loss: 4.469336986541748\n","Epoch [24/1000] Step [450/600] d_loss: 0.05467933043837547 g_loss: 5.499908447265625\n","Epoch [24/1000] Step [600/600] d_loss: 0.04608955979347229 g_loss: 5.749155044555664\n","Epoch [25/1000] Step [150/600] d_loss: 0.062051478773355484 g_loss: 4.732945919036865\n","Epoch [25/1000] Step [300/600] d_loss: 0.1026790663599968 g_loss: 5.579345703125\n","Epoch [25/1000] Step [450/600] d_loss: 0.09307822585105896 g_loss: 5.540859699249268\n","Epoch [25/1000] Step [600/600] d_loss: 0.15587419271469116 g_loss: 4.318155765533447\n","Epoch [26/1000] Step [150/600] d_loss: 0.11994658410549164 g_loss: 4.539192199707031\n","Epoch [26/1000] Step [300/600] d_loss: 0.09414990246295929 g_loss: 4.2659125328063965\n","Epoch [26/1000] Step [450/600] d_loss: 0.09160399436950684 g_loss: 5.169070243835449\n","Epoch [26/1000] Step [600/600] d_loss: 0.05621034651994705 g_loss: 5.127564430236816\n","Epoch [27/1000] Step [150/600] d_loss: 0.07993479073047638 g_loss: 6.466771125793457\n","Epoch [27/1000] Step [300/600] d_loss: 0.0795505940914154 g_loss: 4.65310001373291\n","Epoch [27/1000] Step [450/600] d_loss: 0.05475112795829773 g_loss: 5.78167200088501\n","Epoch [27/1000] Step [600/600] d_loss: 0.14344289898872375 g_loss: 3.3281590938568115\n","Epoch [28/1000] Step [150/600] d_loss: 0.05276627838611603 g_loss: 8.235430717468262\n","Epoch [28/1000] Step [300/600] d_loss: 0.06925532966852188 g_loss: 5.962424278259277\n","Epoch [28/1000] Step [450/600] d_loss: 0.0333930142223835 g_loss: 7.409762859344482\n","Epoch [28/1000] Step [600/600] d_loss: 0.04500412568449974 g_loss: 6.473783493041992\n","Epoch [29/1000] Step [150/600] d_loss: 0.03380129113793373 g_loss: 5.559953689575195\n","Epoch [29/1000] Step [300/600] d_loss: 0.06439061462879181 g_loss: 4.977535724639893\n","Epoch [29/1000] Step [450/600] d_loss: 0.06027869135141373 g_loss: 4.779354572296143\n","Epoch [29/1000] Step [600/600] d_loss: 0.032571978867053986 g_loss: 5.232997417449951\n","Epoch [30/1000] Step [150/600] d_loss: 0.10273633152246475 g_loss: 5.332463264465332\n","Epoch [30/1000] Step [300/600] d_loss: 0.1451893448829651 g_loss: 5.7237701416015625\n","Epoch [30/1000] Step [450/600] d_loss: 0.1435568481683731 g_loss: 4.487857341766357\n","Epoch [30/1000] Step [600/600] d_loss: 0.05234125256538391 g_loss: 5.152021884918213\n","Epoch [31/1000] Step [150/600] d_loss: 0.12060710042715073 g_loss: 4.867853164672852\n","Epoch [31/1000] Step [300/600] d_loss: 0.08706732094287872 g_loss: 7.072117805480957\n","Epoch [31/1000] Step [450/600] d_loss: 0.09575505554676056 g_loss: 5.1073808670043945\n","Epoch [31/1000] Step [600/600] d_loss: 0.07756407558917999 g_loss: 4.264348983764648\n","Epoch [32/1000] Step [150/600] d_loss: 0.11462250351905823 g_loss: 6.143498420715332\n","Epoch [32/1000] Step [300/600] d_loss: 0.08075368404388428 g_loss: 4.6790337562561035\n","Epoch [32/1000] Step [450/600] d_loss: 0.15764740109443665 g_loss: 4.223740577697754\n","Epoch [32/1000] Step [600/600] d_loss: 0.11749976128339767 g_loss: 5.207437038421631\n","Epoch [33/1000] Step [150/600] d_loss: 0.1424006223678589 g_loss: 4.210452556610107\n","Epoch [33/1000] Step [300/600] d_loss: 0.05644494295120239 g_loss: 6.0946044921875\n","Epoch [33/1000] Step [450/600] d_loss: 0.061891380697488785 g_loss: 5.019015789031982\n","Epoch [33/1000] Step [600/600] d_loss: 0.08156430721282959 g_loss: 3.582646369934082\n","Epoch [34/1000] Step [150/600] d_loss: 0.058306314051151276 g_loss: 5.544610977172852\n","Epoch [34/1000] Step [300/600] d_loss: 0.11596693098545074 g_loss: 4.512313365936279\n","Epoch [34/1000] Step [450/600] d_loss: 0.08912459015846252 g_loss: 5.047809600830078\n","Epoch [34/1000] Step [600/600] d_loss: 0.16394449770450592 g_loss: 3.900912046432495\n","Epoch [35/1000] Step [150/600] d_loss: 0.0609276108443737 g_loss: 5.85120964050293\n","Epoch [35/1000] Step [300/600] d_loss: 0.06368203461170197 g_loss: 6.830018997192383\n","Epoch [35/1000] Step [450/600] d_loss: 0.08926207572221756 g_loss: 4.842957496643066\n","Epoch [35/1000] Step [600/600] d_loss: 0.09745897352695465 g_loss: 5.473016262054443\n","Epoch [36/1000] Step [150/600] d_loss: 0.12517201900482178 g_loss: 4.2129130363464355\n","Epoch [36/1000] Step [300/600] d_loss: 0.10325156152248383 g_loss: 5.375579833984375\n","Epoch [36/1000] Step [450/600] d_loss: 0.07889565825462341 g_loss: 4.7423014640808105\n","Epoch [36/1000] Step [600/600] d_loss: 0.07877063006162643 g_loss: 5.529258728027344\n","Epoch [37/1000] Step [150/600] d_loss: 0.15526866912841797 g_loss: 5.124355316162109\n","Epoch [37/1000] Step [300/600] d_loss: 0.10420311242341995 g_loss: 5.21013069152832\n","Epoch [37/1000] Step [450/600] d_loss: 0.17162679135799408 g_loss: 5.19541072845459\n","Epoch [37/1000] Step [600/600] d_loss: 0.1326361447572708 g_loss: 3.9894514083862305\n","Epoch [38/1000] Step [150/600] d_loss: 0.22068367898464203 g_loss: 3.1499505043029785\n","Epoch [38/1000] Step [300/600] d_loss: 0.15395274758338928 g_loss: 3.132155656814575\n","Epoch [38/1000] Step [450/600] d_loss: 0.10702916234731674 g_loss: 3.7331206798553467\n","Epoch [38/1000] Step [600/600] d_loss: 0.12089364975690842 g_loss: 6.148443698883057\n","Epoch [39/1000] Step [150/600] d_loss: 0.14296209812164307 g_loss: 5.096052646636963\n","Epoch [39/1000] Step [300/600] d_loss: 0.11988191306591034 g_loss: 3.9839086532592773\n","Epoch [39/1000] Step [450/600] d_loss: 0.1336158812046051 g_loss: 3.9890801906585693\n","Epoch [39/1000] Step [600/600] d_loss: 0.11939169466495514 g_loss: 5.2424116134643555\n","Epoch [40/1000] Step [150/600] d_loss: 0.11920032650232315 g_loss: 4.441880226135254\n","Epoch [40/1000] Step [300/600] d_loss: 0.08670914173126221 g_loss: 6.142179012298584\n","Epoch [40/1000] Step [450/600] d_loss: 0.054092660546302795 g_loss: 5.839325428009033\n","Epoch [40/1000] Step [600/600] d_loss: 0.049802206456661224 g_loss: 5.991580486297607\n","Epoch [41/1000] Step [150/600] d_loss: 0.18787261843681335 g_loss: 4.48512077331543\n","Epoch [41/1000] Step [300/600] d_loss: 0.12259037792682648 g_loss: 5.583906173706055\n","Epoch [41/1000] Step [450/600] d_loss: 0.09033108502626419 g_loss: 4.820174217224121\n","Epoch [41/1000] Step [600/600] d_loss: 0.1998913288116455 g_loss: 5.155175685882568\n","Epoch [42/1000] Step [150/600] d_loss: 0.16770493984222412 g_loss: 5.954104900360107\n","Epoch [42/1000] Step [300/600] d_loss: 0.07371728122234344 g_loss: 4.6166510581970215\n","Epoch [42/1000] Step [450/600] d_loss: 0.09117946028709412 g_loss: 4.240228652954102\n","Epoch [42/1000] Step [600/600] d_loss: 0.1536969095468521 g_loss: 3.8834712505340576\n","Epoch [43/1000] Step [150/600] d_loss: 0.137217178940773 g_loss: 3.405379056930542\n","Epoch [43/1000] Step [300/600] d_loss: 0.130963996052742 g_loss: 2.9270989894866943\n","Epoch [43/1000] Step [450/600] d_loss: 0.18000584840774536 g_loss: 3.375494956970215\n","Epoch [43/1000] Step [600/600] d_loss: 0.1861569881439209 g_loss: 4.605539321899414\n","Epoch [44/1000] Step [150/600] d_loss: 0.17323188483715057 g_loss: 3.7110705375671387\n","Epoch [44/1000] Step [300/600] d_loss: 0.17778022587299347 g_loss: 4.49213981628418\n","Epoch [44/1000] Step [450/600] d_loss: 0.1988709568977356 g_loss: 2.8079628944396973\n","Epoch [44/1000] Step [600/600] d_loss: 0.15229880809783936 g_loss: 2.6839189529418945\n","Epoch [45/1000] Step [150/600] d_loss: 0.3479020893573761 g_loss: 4.264153480529785\n","Epoch [45/1000] Step [300/600] d_loss: 0.19679144024848938 g_loss: 3.2457363605499268\n","Epoch [45/1000] Step [450/600] d_loss: 0.2672910690307617 g_loss: 3.4763505458831787\n","Epoch [45/1000] Step [600/600] d_loss: 0.14301848411560059 g_loss: 3.074418306350708\n","Epoch [46/1000] Step [150/600] d_loss: 0.19694951176643372 g_loss: 3.2805943489074707\n","Epoch [46/1000] Step [300/600] d_loss: 0.20779788494110107 g_loss: 2.5057430267333984\n","Epoch [46/1000] Step [450/600] d_loss: 0.32084396481513977 g_loss: 3.9649999141693115\n","Epoch [46/1000] Step [600/600] d_loss: 0.18606214225292206 g_loss: 2.74605131149292\n","Epoch [47/1000] Step [150/600] d_loss: 0.2493530660867691 g_loss: 2.5295605659484863\n","Epoch [47/1000] Step [300/600] d_loss: 0.30048441886901855 g_loss: 3.1755776405334473\n","Epoch [47/1000] Step [450/600] d_loss: 0.2842120826244354 g_loss: 3.0233025550842285\n","Epoch [47/1000] Step [600/600] d_loss: 0.27876847982406616 g_loss: 3.2114152908325195\n","Epoch [48/1000] Step [150/600] d_loss: 0.20815980434417725 g_loss: 2.4764599800109863\n","Epoch [48/1000] Step [300/600] d_loss: 0.19432416558265686 g_loss: 2.263268232345581\n","Epoch [48/1000] Step [450/600] d_loss: 0.2259194254875183 g_loss: 2.9899282455444336\n","Epoch [48/1000] Step [600/600] d_loss: 0.1549299955368042 g_loss: 2.886683702468872\n","Epoch [49/1000] Step [150/600] d_loss: 0.18692733347415924 g_loss: 2.8711090087890625\n","Epoch [49/1000] Step [300/600] d_loss: 0.2873712182044983 g_loss: 1.8000378608703613\n","Epoch [49/1000] Step [450/600] d_loss: 0.25533339381217957 g_loss: 2.781632423400879\n","Epoch [49/1000] Step [600/600] d_loss: 0.26971080899238586 g_loss: 2.74971342086792\n","Epoch [50/1000] Step [150/600] d_loss: 0.22220388054847717 g_loss: 3.5902955532073975\n","Epoch [50/1000] Step [300/600] d_loss: 0.1872619092464447 g_loss: 3.420654773712158\n","Epoch [50/1000] Step [450/600] d_loss: 0.18494880199432373 g_loss: 2.7543959617614746\n","Epoch [50/1000] Step [600/600] d_loss: 0.15441963076591492 g_loss: 3.364593982696533\n","Epoch [51/1000] Step [150/600] d_loss: 0.1391606628894806 g_loss: 4.116668701171875\n","Epoch [51/1000] Step [300/600] d_loss: 0.1970001459121704 g_loss: 2.955687999725342\n","Epoch [51/1000] Step [450/600] d_loss: 0.1722562611103058 g_loss: 3.232583522796631\n","Epoch [51/1000] Step [600/600] d_loss: 0.1716509759426117 g_loss: 4.24176025390625\n","Epoch [52/1000] Step [150/600] d_loss: 0.07289327681064606 g_loss: 5.653922080993652\n","Epoch [52/1000] Step [300/600] d_loss: 0.05094891041517258 g_loss: 6.041210651397705\n","Epoch [52/1000] Step [450/600] d_loss: 0.07192550599575043 g_loss: 8.237284660339355\n","Epoch [52/1000] Step [600/600] d_loss: 0.0485927015542984 g_loss: 7.391695499420166\n","Epoch [53/1000] Step [150/600] d_loss: 0.12590521574020386 g_loss: 5.788967132568359\n","Epoch [53/1000] Step [300/600] d_loss: 0.09240667521953583 g_loss: 5.955037593841553\n","Epoch [53/1000] Step [450/600] d_loss: 0.12830978631973267 g_loss: 4.647008419036865\n","Epoch [53/1000] Step [600/600] d_loss: 0.18032048642635345 g_loss: 4.740546226501465\n","Epoch [54/1000] Step [150/600] d_loss: 0.20849958062171936 g_loss: 2.9623143672943115\n","Epoch [54/1000] Step [300/600] d_loss: 0.19921855628490448 g_loss: 3.135315418243408\n","Epoch [54/1000] Step [450/600] d_loss: 0.16935007274150848 g_loss: 4.43270206451416\n","Epoch [54/1000] Step [600/600] d_loss: 0.19939161837100983 g_loss: 3.4898440837860107\n","Epoch [55/1000] Step [150/600] d_loss: 0.2627340853214264 g_loss: 3.956325054168701\n","Epoch [55/1000] Step [300/600] d_loss: 0.21628938615322113 g_loss: 3.570596933364868\n","Epoch [55/1000] Step [450/600] d_loss: 0.19721201062202454 g_loss: 3.1143343448638916\n","Epoch [55/1000] Step [600/600] d_loss: 0.227979376912117 g_loss: 3.5919203758239746\n","Epoch [56/1000] Step [150/600] d_loss: 0.22148564457893372 g_loss: 2.8662540912628174\n","Epoch [56/1000] Step [300/600] d_loss: 0.26261889934539795 g_loss: 2.501084327697754\n","Epoch [56/1000] Step [450/600] d_loss: 0.35073286294937134 g_loss: 2.4401211738586426\n","Epoch [56/1000] Step [600/600] d_loss: 0.24303951859474182 g_loss: 3.0045595169067383\n","Epoch [57/1000] Step [150/600] d_loss: 0.3197063207626343 g_loss: 2.4946892261505127\n","Epoch [57/1000] Step [300/600] d_loss: 0.2458631694316864 g_loss: 2.8519747257232666\n","Epoch [57/1000] Step [450/600] d_loss: 0.2072029858827591 g_loss: 2.691321849822998\n","Epoch [57/1000] Step [600/600] d_loss: 0.19609859585762024 g_loss: 2.7524313926696777\n","Epoch [58/1000] Step [150/600] d_loss: 0.22819122672080994 g_loss: 3.0985870361328125\n","Epoch [58/1000] Step [300/600] d_loss: 0.33546093106269836 g_loss: 3.565265417098999\n","Epoch [58/1000] Step [450/600] d_loss: 0.2622198462486267 g_loss: 3.727257013320923\n","Epoch [58/1000] Step [600/600] d_loss: 0.31588953733444214 g_loss: 1.97844660282135\n","Epoch [59/1000] Step [150/600] d_loss: 0.2487342655658722 g_loss: 2.4713387489318848\n","Epoch [59/1000] Step [300/600] d_loss: 0.25564736127853394 g_loss: 3.0572450160980225\n","Epoch [59/1000] Step [450/600] d_loss: 0.2690306305885315 g_loss: 3.7113137245178223\n","Epoch [59/1000] Step [600/600] d_loss: 0.1901944875717163 g_loss: 2.998379945755005\n","Epoch [60/1000] Step [150/600] d_loss: 0.25750136375427246 g_loss: 2.763847589492798\n","Epoch [60/1000] Step [300/600] d_loss: 0.2498336136341095 g_loss: 2.6778554916381836\n","Epoch [60/1000] Step [450/600] d_loss: 0.20289112627506256 g_loss: 3.4489517211914062\n","Epoch [60/1000] Step [600/600] d_loss: 0.19904249906539917 g_loss: 3.154350519180298\n","Epoch [61/1000] Step [150/600] d_loss: 0.23954465985298157 g_loss: 3.0934484004974365\n","Epoch [61/1000] Step [300/600] d_loss: 0.25340044498443604 g_loss: 2.8309741020202637\n","Epoch [61/1000] Step [450/600] d_loss: 0.26129767298698425 g_loss: 2.753757953643799\n","Epoch [61/1000] Step [600/600] d_loss: 0.3060271143913269 g_loss: 2.3488376140594482\n","Epoch [62/1000] Step [150/600] d_loss: 0.2596449851989746 g_loss: 3.231847047805786\n","Epoch [62/1000] Step [300/600] d_loss: 0.25573742389678955 g_loss: 3.034099578857422\n","Epoch [62/1000] Step [450/600] d_loss: 0.20613417029380798 g_loss: 2.984471321105957\n","Epoch [62/1000] Step [600/600] d_loss: 0.26424527168273926 g_loss: 2.407552719116211\n","Epoch [63/1000] Step [150/600] d_loss: 0.22618332505226135 g_loss: 3.4276835918426514\n","Epoch [63/1000] Step [300/600] d_loss: 0.22911934554576874 g_loss: 3.0017037391662598\n","Epoch [63/1000] Step [450/600] d_loss: 0.28611546754837036 g_loss: 3.688896894454956\n","Epoch [63/1000] Step [600/600] d_loss: 0.20781457424163818 g_loss: 3.353076696395874\n","Epoch [64/1000] Step [150/600] d_loss: 0.1825876533985138 g_loss: 3.810275077819824\n","Epoch [64/1000] Step [300/600] d_loss: 0.2441886067390442 g_loss: 2.6287670135498047\n","Epoch [64/1000] Step [450/600] d_loss: 0.1648331880569458 g_loss: 3.5808663368225098\n","Epoch [64/1000] Step [600/600] d_loss: 0.14714086055755615 g_loss: 3.50175404548645\n","Epoch [65/1000] Step [150/600] d_loss: 0.21741154789924622 g_loss: 3.7558934688568115\n","Epoch [65/1000] Step [300/600] d_loss: 0.19694185256958008 g_loss: 4.812033653259277\n","Epoch [65/1000] Step [450/600] d_loss: 0.15489882230758667 g_loss: 4.500848770141602\n","Epoch [65/1000] Step [600/600] d_loss: 0.12508055567741394 g_loss: 4.817371368408203\n","Epoch [66/1000] Step [150/600] d_loss: 0.1356118768453598 g_loss: 4.864166736602783\n","Epoch [66/1000] Step [300/600] d_loss: 0.08535092324018478 g_loss: 4.8620781898498535\n","Epoch [66/1000] Step [450/600] d_loss: 0.0439310297369957 g_loss: 5.817705154418945\n","Epoch [66/1000] Step [600/600] d_loss: 0.049394816160202026 g_loss: 5.911639213562012\n","Epoch [67/1000] Step [150/600] d_loss: 0.04805833846330643 g_loss: 5.254340171813965\n","Epoch [67/1000] Step [300/600] d_loss: 0.07279644906520844 g_loss: 6.87652587890625\n","Epoch [67/1000] Step [450/600] d_loss: 0.08158351480960846 g_loss: 5.634022235870361\n","Epoch [67/1000] Step [600/600] d_loss: 0.10443584620952606 g_loss: 4.825308322906494\n","Epoch [68/1000] Step [150/600] d_loss: 0.1679524928331375 g_loss: 4.3970112800598145\n","Epoch [68/1000] Step [300/600] d_loss: 0.1955564171075821 g_loss: 3.236713409423828\n","Epoch [68/1000] Step [450/600] d_loss: 0.1977684497833252 g_loss: 3.689258098602295\n","Epoch [68/1000] Step [600/600] d_loss: 0.26337355375289917 g_loss: 4.098633289337158\n","Epoch [69/1000] Step [150/600] d_loss: 0.440178245306015 g_loss: 3.7080419063568115\n","Epoch [69/1000] Step [300/600] d_loss: 0.34266579151153564 g_loss: 2.7433135509490967\n","Epoch [69/1000] Step [450/600] d_loss: 0.23244282603263855 g_loss: 2.2356467247009277\n","Epoch [69/1000] Step [600/600] d_loss: 0.2726096510887146 g_loss: 2.146980047225952\n","Epoch [70/1000] Step [150/600] d_loss: 0.2588152587413788 g_loss: 3.7203404903411865\n","Epoch [70/1000] Step [300/600] d_loss: 0.17122629284858704 g_loss: 3.127427339553833\n","Epoch [70/1000] Step [450/600] d_loss: 0.2736298739910126 g_loss: 2.776280641555786\n","Epoch [70/1000] Step [600/600] d_loss: 0.23647896945476532 g_loss: 2.888925075531006\n","Epoch [71/1000] Step [150/600] d_loss: 0.23143215477466583 g_loss: 2.7179510593414307\n","Epoch [71/1000] Step [300/600] d_loss: 0.19975052773952484 g_loss: 2.8700103759765625\n","Epoch [71/1000] Step [450/600] d_loss: 0.29721537232398987 g_loss: 2.7610831260681152\n","Epoch [71/1000] Step [600/600] d_loss: 0.20932352542877197 g_loss: 2.159959077835083\n","Epoch [72/1000] Step [150/600] d_loss: 0.33579540252685547 g_loss: 2.3862411975860596\n","Epoch [72/1000] Step [300/600] d_loss: 0.28895020484924316 g_loss: 3.217634439468384\n","Epoch [72/1000] Step [450/600] d_loss: 0.2687796652317047 g_loss: 2.561306953430176\n","Epoch [72/1000] Step [600/600] d_loss: 0.20456171035766602 g_loss: 2.460916757583618\n","Epoch [73/1000] Step [150/600] d_loss: 0.23633673787117004 g_loss: 2.7061126232147217\n","Epoch [73/1000] Step [300/600] d_loss: 0.2708899974822998 g_loss: 2.189194917678833\n","Epoch [73/1000] Step [450/600] d_loss: 0.24764657020568848 g_loss: 2.1964404582977295\n","Epoch [73/1000] Step [600/600] d_loss: 0.3506532311439514 g_loss: 2.999905824661255\n","Epoch [74/1000] Step [150/600] d_loss: 0.2858673334121704 g_loss: 2.3403406143188477\n","Epoch [74/1000] Step [300/600] d_loss: 0.30016663670539856 g_loss: 3.2558205127716064\n","Epoch [74/1000] Step [450/600] d_loss: 0.3703992962837219 g_loss: 2.3329012393951416\n","Epoch [74/1000] Step [600/600] d_loss: 0.2626922130584717 g_loss: 2.6413960456848145\n","Epoch [75/1000] Step [150/600] d_loss: 0.4183795154094696 g_loss: 2.8966712951660156\n","Epoch [75/1000] Step [300/600] d_loss: 0.32336726784706116 g_loss: 2.416720151901245\n","Epoch [75/1000] Step [450/600] d_loss: 0.28749459981918335 g_loss: 2.3325254917144775\n","Epoch [75/1000] Step [600/600] d_loss: 0.4089009165763855 g_loss: 1.7073737382888794\n","Epoch [76/1000] Step [150/600] d_loss: 0.38041090965270996 g_loss: 2.513367176055908\n","Epoch [76/1000] Step [300/600] d_loss: 0.34940528869628906 g_loss: 2.30269193649292\n","Epoch [76/1000] Step [450/600] d_loss: 0.30467599630355835 g_loss: 2.0677928924560547\n","Epoch [76/1000] Step [600/600] d_loss: 0.3417346775531769 g_loss: 2.0979175567626953\n","Epoch [77/1000] Step [150/600] d_loss: 0.36817753314971924 g_loss: 2.8990886211395264\n","Epoch [77/1000] Step [300/600] d_loss: 0.32299381494522095 g_loss: 2.543951988220215\n","Epoch [77/1000] Step [450/600] d_loss: 0.45294618606567383 g_loss: 2.6100997924804688\n","Epoch [77/1000] Step [600/600] d_loss: 0.2984316349029541 g_loss: 2.2349002361297607\n","Epoch [78/1000] Step [150/600] d_loss: 0.3048536777496338 g_loss: 2.1458022594451904\n","Epoch [78/1000] Step [300/600] d_loss: 0.3481457233428955 g_loss: 2.0624618530273438\n","Epoch [78/1000] Step [450/600] d_loss: 0.3225906491279602 g_loss: 1.8239035606384277\n","Epoch [78/1000] Step [600/600] d_loss: 0.3392382562160492 g_loss: 1.5515367984771729\n","Epoch [79/1000] Step [150/600] d_loss: 0.29314756393432617 g_loss: 1.9933109283447266\n","Epoch [79/1000] Step [300/600] d_loss: 0.35622158646583557 g_loss: 3.1111743450164795\n","Epoch [79/1000] Step [450/600] d_loss: 0.3389040231704712 g_loss: 2.4637293815612793\n","Epoch [79/1000] Step [600/600] d_loss: 0.3600774109363556 g_loss: 2.2549824714660645\n","Epoch [80/1000] Step [150/600] d_loss: 0.3988823890686035 g_loss: 1.690882682800293\n","Epoch [80/1000] Step [300/600] d_loss: 0.3557010293006897 g_loss: 1.7752370834350586\n","Epoch [80/1000] Step [450/600] d_loss: 0.2656595706939697 g_loss: 2.1546266078948975\n","Epoch [80/1000] Step [600/600] d_loss: 0.3149755299091339 g_loss: 2.8199708461761475\n","Epoch [81/1000] Step [150/600] d_loss: 0.30586811900138855 g_loss: 1.8317331075668335\n","Epoch [81/1000] Step [300/600] d_loss: 0.3992398977279663 g_loss: 1.9277575016021729\n","Epoch [81/1000] Step [450/600] d_loss: 0.32105761766433716 g_loss: 2.5376222133636475\n","Epoch [81/1000] Step [600/600] d_loss: 0.42514097690582275 g_loss: 2.5085933208465576\n","Epoch [82/1000] Step [150/600] d_loss: 0.3568546175956726 g_loss: 1.9007582664489746\n","Epoch [82/1000] Step [300/600] d_loss: 0.2965083122253418 g_loss: 1.9996954202651978\n","Epoch [82/1000] Step [450/600] d_loss: 0.4139249622821808 g_loss: 2.1623778343200684\n","Epoch [82/1000] Step [600/600] d_loss: 0.2730679214000702 g_loss: 2.6621861457824707\n","Epoch [83/1000] Step [150/600] d_loss: 0.31056609749794006 g_loss: 3.130497694015503\n","Epoch [83/1000] Step [300/600] d_loss: 0.30387651920318604 g_loss: 2.154547929763794\n","Epoch [83/1000] Step [450/600] d_loss: 0.3901240825653076 g_loss: 2.931659460067749\n","Epoch [83/1000] Step [600/600] d_loss: 0.29879143834114075 g_loss: 2.0644094944000244\n","Epoch [84/1000] Step [150/600] d_loss: 0.2939210534095764 g_loss: 2.286088705062866\n","Epoch [84/1000] Step [300/600] d_loss: 0.24231621623039246 g_loss: 2.7528536319732666\n","Epoch [84/1000] Step [450/600] d_loss: 0.24220174551010132 g_loss: 3.071310043334961\n","Epoch [84/1000] Step [600/600] d_loss: 0.32177889347076416 g_loss: 2.5542776584625244\n","Epoch [85/1000] Step [150/600] d_loss: 0.34101876616477966 g_loss: 2.0001187324523926\n","Epoch [85/1000] Step [300/600] d_loss: 0.20562335848808289 g_loss: 2.175283670425415\n","Epoch [85/1000] Step [450/600] d_loss: 0.2733329236507416 g_loss: 3.1240041255950928\n","Epoch [85/1000] Step [600/600] d_loss: 0.27825677394866943 g_loss: 2.735372304916382\n","Epoch [86/1000] Step [150/600] d_loss: 0.3226727545261383 g_loss: 2.600806713104248\n","Epoch [86/1000] Step [300/600] d_loss: 0.2678925693035126 g_loss: 2.977221965789795\n","Epoch [86/1000] Step [450/600] d_loss: 0.3061726987361908 g_loss: 1.8163671493530273\n","Epoch [86/1000] Step [600/600] d_loss: 0.26980894804000854 g_loss: 2.7952873706817627\n","Epoch [87/1000] Step [150/600] d_loss: 0.3909781575202942 g_loss: 1.6363506317138672\n","Epoch [87/1000] Step [300/600] d_loss: 0.29853326082229614 g_loss: 2.4128143787384033\n","Epoch [87/1000] Step [450/600] d_loss: 0.3680835962295532 g_loss: 1.9534341096878052\n","Epoch [87/1000] Step [600/600] d_loss: 0.23261341452598572 g_loss: 2.3124616146087646\n","Epoch [88/1000] Step [150/600] d_loss: 0.33675599098205566 g_loss: 3.0119481086730957\n","Epoch [88/1000] Step [300/600] d_loss: 0.2675340175628662 g_loss: 2.716911554336548\n","Epoch [88/1000] Step [450/600] d_loss: 0.3491799831390381 g_loss: 1.7518078088760376\n","Epoch [88/1000] Step [600/600] d_loss: 0.21962100267410278 g_loss: 2.5583956241607666\n","Epoch [89/1000] Step [150/600] d_loss: 0.25055959820747375 g_loss: 2.292198657989502\n","Epoch [89/1000] Step [300/600] d_loss: 0.3731764853000641 g_loss: 2.7781951427459717\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-96766230cba0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m150\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compiling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             torch._foreach_add_(\n\u001b[0m\u001b[1;32m    602\u001b[0m                 \u001b[0mdevice_state_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             )\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "folder = 'fig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'bamboo.jpg'))\n",
    "\n",
    "if src is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "\n",
    "## blurring\n",
    "kernel_3 = np.ones((3, 3), np.float32)/9.\n",
    "dst = cv2.filter2D(src, -1, kernel_3)\n",
    "dst_blur = cv2.blur(src, (3, 3))\n",
    "\n",
    "## Gaussian\n",
    "blur_sig1 = cv2.GaussianBlur(src, (0, 0), 1)\n",
    "blur_sig2 = cv2.GaussianBlur(src, (0, 0), 2)\n",
    "\n",
    "## sharpening\n",
    "sharp_sig1 = cv2.addWeighted(src, 2, blur_sig1, -1, 0.0)\n",
    "sharp_sig2 = cv2.addWeighted(src, 2, blur_sig2, -1, 0.0)\n",
    "\n",
    "cv2.namedWindow('src', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.imshow('src', src)\n",
    "# cv2.imshow('dst', dst)\n",
    "# cv2.imshow('dst_blur', dst_blur)\n",
    "# cv2.imshow('blur_sig1', blur_sig1)\n",
    "# cv2.imshow('blur_sig2', blur_sig2)\n",
    "cv2.imshow('sharp_sig1', sharp_sig1)\n",
    "cv2.imshow('sharp_sig2', sharp_sig2)\n",
    "\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rot matrix = \n",
      " [[  0.93969262  -0.34202014  51.49792289]\n",
      " [  0.34202014   0.93969262 -36.05923381]]\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread(Path(folder, 'spades.png'), cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "## transform\n",
    "affine = np.array([[1, 0, 100],\n",
    "                   [0, 1, 50]], np.float32)\n",
    "dst_trans = cv2.warpAffine(src, affine, (w+100, h+50))\n",
    "\n",
    "## rotation\n",
    "h, w = src.shape[:2]\n",
    "rot_mat = cv2.getRotationMatrix2D((w//2, h//2), -20, 1.0)\n",
    "print(\"rot matrix = \\n\", rot_mat)\n",
    "dst_rot = cv2.warpAffine(src, rot_mat, (0, 0))\n",
    "\n",
    "## 영상 확대\n",
    "affine_scale = np.array([[1.2, 0, 0],\n",
    "                         [0, 1.4, 0]], np.float32)\n",
    "dst_scale = cv2.warpAffine(src, affine_scale, (int(w*1.2),int( h*1.4)))\n",
    "\n",
    "## shear, skew, 전단 변환\n",
    "affine_shear = np.array([[1, 0.2, 0],\n",
    "                         [0, 1, 0]], np.float32)\n",
    "dst_shear = cv2.warpAffine(src, affine_shear, (w+int(h*0.2), h))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst_trans\", dst_trans)\n",
    "cv2.imshow(\"dst_rot\", dst_rot)\n",
    "cv2.imshow(\"dst_scale\", dst_scale)\n",
    "cv2.imshow(\"dst_shear\", dst_shear)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'son.jpg'))\n",
    "\n",
    "dst1 = cv2.resize(src, (0, 0), fx=3, fy=3, interpolation=cv2.INTER_NEAREST)\n",
    "dst2 = cv2.resize(src, (0, 0), fx=3, fy=3, interpolation=cv2.INTER_LINEAR)\n",
    "dst3 = cv2.resize(src, (0, 0), fx=3, fy=3, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst1\", dst1)\n",
    "cv2.imshow(\"dst2\", dst2)\n",
    "cv2.imshow(\"dst3\", dst3)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비선형 변환 (Perspective transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getPerspectiveTransform(src, dst[, solveMethod]) -> retval\n",
    "# src: 입력영상의 4개 좌표점, numpy array shape(4,2)\n",
    "# dst: 출력영상의 4개 좌표점, numpy array shape(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pers transforms matrix = \n",
      " [[ 2.13761247e+00  6.70798891e-01 -4.98868663e+02]\n",
      " [ 8.22754210e-03  1.94581371e+00 -9.71384758e+01]\n",
      " [-1.69199517e-05  1.37469054e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "src = cv2.imread(Path(folder, 'checkerboard.png'))\n",
    "\n",
    "# roi = cv2.selectROI(src)\n",
    "# print('roi coor = ', roi)\n",
    "\n",
    "src_lists = [[218, 49], [691, 47], [832, 516], [68, 527]]\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "srcPoints = np.array(src_lists, np.float32)\n",
    "dstPoints = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], np.float32)\n",
    "\n",
    "pers_mat = cv2.getPerspectiveTransform(srcPoints, dstPoints)\n",
    "\n",
    "print(\"pers transforms matrix = \\n\", pers_mat)\n",
    "\n",
    "dst = cv2.warpPerspective(src, pers_mat, (w, h))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 객체 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(Path(folder, \"bamboo.jpg\"), cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.imread(Path(folder, \"plates.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sobel_kernelx = np.array([[-1, 0, 1],\n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]], np.float32)\n",
    "sobel_kernely = sobel_kernelx.T\n",
    "\n",
    "sobel_dx = cv2.filter2D(img, -1, sobel_kernelx)\n",
    "sobel_dy = cv2.filter2D(img, -1, sobel_kernely)\n",
    "# sobel_dx = cv2.absdiff(sobel_dx, )\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('sobel_dx', sobel_dx)\n",
    "cv2.imshow('sobel_dy', sobel_dy)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sobel filter\n",
    "# cv2.Sobel(src, ddepth, dx, dy, dst, ksize, scale, delt, borderType) -> dst\n",
    "# src : 입력영상\n",
    "# ddepth : 출력영상의 데이터 타입 (-1)\n",
    "# dx : x 방향 미분차수\n",
    "# dy : x 방향 미분차수\n",
    "# dst : 출력영상\n",
    "# ksize : 커널의 크기\n",
    "# scale : 연산결과에 추가적으로 곱할 값\n",
    "# delta : 연산결과에 추가적으로 더할 값\n",
    "# borderType : 가장자리 픽셀확장 방식\n",
    "\n",
    "# magnitude(x, y, magnitude) -> magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src = cv2.imread(Path(folder, 'son.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread(Path(folder, \"plates.png\"), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "dx = cv2.Sobel(src, cv2.CV_32F, 1, 0)\n",
    "dy = cv2.Sobel(src, cv2.CV_32F, 0, 1)\n",
    "\n",
    "## magnitude, direction\n",
    "mag = cv2.magnitude(dx, dy)\n",
    "mag = np.clip(mag, 0, 255).astype(np.uint8)\n",
    "\n",
    "ret, dst = cv2.threshold(mag, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "dst_canny = cv2.Canny(src, 150, 200)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('mag', mag)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.imshow('dst_canny', dst_canny)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough transforms, 직선 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 직선 검출, 곡선 검출; 허프 변환 (Hough transform)\n",
    "# HoughLinesP(image, rho, theta, threshold, lines, minLineLength, maxLineGap) -> lines\n",
    "# image: 입력 에지영상\n",
    "# rho: 축적배열에서 rho의 간격\n",
    "# theta: 축적배열에서 theta의 간격\n",
    "# threshold: 직선판단할 임계값\n",
    "# lines: 선분의 끝좌표 (x1, y1, x2, y2)\n",
    "# srn = None, stn = None\n",
    "# minLineLength: 검출한 선분의 최소 길이\n",
    "# maxLineGap: 직선으로 간주할 최대 에지 점 간격 (끝어진 점을 연결할 기준)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread(Path(folder, 'checkerboard.png'))\n",
    "img = cv2.imread(Path(folder, 'plates.png'))\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edge = cv2.Canny(img_gray, 100, 200)\n",
    "\n",
    "lines = cv2.HoughLinesP(edge, 1, np.pi/360, 69, minLineLength=20, maxLineGap=8)\n",
    "print(lines.shape)\n",
    "\n",
    "edge = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in lines:\n",
    "    pt1 = (i[0, 0], i[0, 1])\n",
    "    pt2 = (i[0, 2], i[0, 3])\n",
    "    cv2.line(edge, pt1, pt2, (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_gray', img_gray)\n",
    "cv2.imshow('edge', edge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread(Path(folder, 'checkerboard.png'))\n",
    "# img = cv2.imread(Path(folder, 'plates.png'))\n",
    "img = cv2.imread(Path(folder, 'door.png'), cv2.IMREAD_REDUCED_COLOR_2)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edge = cv2.Canny(img_gray, 100, 200)\n",
    "\n",
    "lines = cv2.HoughLinesP(edge, 1, np.pi/360, 69, minLineLength=20, maxLineGap=8)\n",
    "print(lines.shape)\n",
    "\n",
    "edge = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in lines:\n",
    "    pt1 = (i[0, 0], i[0, 1])\n",
    "    pt2 = (i[0, 2], i[0, 3])\n",
    "    cv2.line(edge, pt1, pt2, (0,255,0), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('img_gray', img_gray)\n",
    "cv2.imshow('edge', edge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough transform : 원 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HoughCircles(image, method, dp, minDist[, circles[, param1[, param2[, minRadius[, maxRadius]]]]]) -> circles\n",
    "# image: 입력영상\n",
    "# method: cv2.HOUGH_GRADIENT,\n",
    "# dp: 입력영상에 대한 실제 영상처리 배율, 1,  2 설정\n",
    "# minDist: 검출된 원들간의 최소거리\n",
    "# circles: 원좌표 (cx, cy, r), shape = (1, N, 3), dtype = np.float32\n",
    "# param1: Canny edge max 값\n",
    "# param2: 축척배열에서 원검출 임계값\n",
    "# minRadius: 원 크기의 최소값\n",
    "# maxRadius: 원 크기의 최대값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'plates.png'))\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "circles = cv2.HoughCircles(src_gray, cv2.HOUGH_GRADIENT, 1, 50, param1=200, param2=50,\n",
    "                           minRadius=50, maxRadius=150)\n",
    "\n",
    "for i in circles[0]:\n",
    "    cx, cy, r = i\n",
    "    cv2.circle(src, (int(cx), int(cy)), int(r), (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "# cv2.imshow('src_gray', src_gray)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 레이블링 (Labeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 레이블링 (labeling)\n",
    "\n",
    "# connectedComponentsWithStats(image[, labels[, stats[, centroids[, connectivity[, ltype]]]]]) -> retval, labels, stats, centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'symbols.png'))\n",
    "# src = cv2.imread(Path(folder, 'shape.png'))\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(src_gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cnts, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "\n",
    "for i in range(1, cnts):\n",
    "    (x, y, w, h, area) = stats[i]\n",
    "\n",
    "    if area > 50:\n",
    "        cv2.rectangle(src, (x, y, w, h), (0, 0, 255), 2)\n",
    "\n",
    "# print('cnts = ', cnts)\n",
    "# print('labels = ', labels)\n",
    "# print('stats = ', stats)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "cv2.imshow('mask', mask)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 외곽선 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 외곽선 검출\n",
    "# findContours(image, mode, method[, contours[, hierarchy[, offset]]]) -> contours, hierarchy\n",
    "    # image: 입력 영상. non-zero 픽셀을 객체로 간주함.\n",
    "    # mode: 외곽선 검출 모드. cv2.RETR_로 시작하는 상수. \n",
    "    #     (cv2.RETR_EXTERNAL, cv2.RETR_LIST,cv2.RETR_CCOMP, cv2.RETR_TREE)\n",
    "    # method: 외곽선 근사화 방법. cv2.CHAIN_APPROX_로 시작하는 상수.\n",
    "    # contour: 검출된 외곽선 좌표. numpy.ndarray로 구성된 리스트. \n",
    "    # contours[i].shape=(K, 1, 2). contours[i].dtype=numpy.int32.\n",
    "    # hierarchy: 외곽선 계층 정보. numpy.ndarray. shape=(1, N, 4). dtype=numpy.int32.\n",
    "    # hierarchy[0, i, 0] ~ hierarchy[0, i, 3]이 순서대로 next, prev, child, parent\n",
    "    # 외곽선 인덱스를 가리킴. 해당 외곽선이 없으면 -1.\n",
    "    # offset: 좌표 값 이동 옵셋. 기본값은 (0, 0).\n",
    "    \n",
    "# drawContours(image, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]) -> image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'plates.png'))\n",
    "# src = cv2.imread(Path(folder, 'shape.png'))\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(src_gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    cv2.drawContours(src, contours, i, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(src, str(i), contours[i][0][0], 0, 0.6, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "cv2.imshow('mask', mask)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(Path(folder, 'img.jpg'))\n",
    "# src = cv2.imread(Path(folder, 'shape.png'))\n",
    "\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "ret, mask = cv2.threshold(src_gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "contours, hierarchy = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for i in range(len(contours)):\n",
    "    cv2.drawContours(src, contours, i, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(src, str(i), contours[i][0][0], 0, 0.6, (0,0,255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "cv2.imshow('mask', mask)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동영상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(Path(folder, 'PETS2000.avi'))\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    # edge = cv2.Canny(frame, 100, 200)\n",
    "    # gaussian = cv2.GaussianBlur(frame, (0, 0), 2)\n",
    "\n",
    "    cv2.imshow('frame', frame)\n",
    "    # cv2.imshow('edge', edge)\n",
    "    # cv2.imshow('gaussian', gaussian)\n",
    "\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_py3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

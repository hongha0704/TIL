{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch custom 데이터셋 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dataset_Class.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dataset_Class.py\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "class PyTorch_Classification_Dataset_Class(Dataset):\n",
    "    def __init__(self\n",
    "                , dataset_dir\n",
    "                , transform):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_abs_path = dataset_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.label_list = os.listdir(self.image_abs_path)\n",
    "        self.label_list.sort()\n",
    "        self.x_list = []\n",
    "        self.y_list = []\n",
    "\n",
    "        for label_index, label_str in enumerate(self.label_list):\n",
    "            img_path = os.path.join(self.image_abs_path, label_str)\n",
    "            img_list = os.listdir(img_path)\n",
    "            for img in img_list:\n",
    "                self.x_list.append(os.path.join(img_path, img))\n",
    "                self.y_list.append(label_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.x_list[idx])\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert('RGB')\n",
    "        # if self.transform is not None:\n",
    "        image = self.transform(image)\n",
    "        return image, self.y_list[idx]\n",
    "    \n",
    "    def __save_label_map__(self, dst_text_path = \"label_map.txt\"):\n",
    "        label_list = self.label_list\n",
    "        f = open(dst_text_path, 'w')\n",
    "        for i in range(len(label_list)):\n",
    "            f.write(label_list[i]+'\\n')\n",
    "        f.close()\n",
    "\n",
    "    def __num_classes__(self):\n",
    "        return len(self.label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Model_Class_From_the_Scratch.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model_Class_From_the_Scratch.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MODEL_From_Scratch(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size = 3, stride = 2, padding = 1)\n",
    "            , nn.BatchNorm2d(32)\n",
    "            , nn.ReLU()\n",
    "            , nn.Conv2d(32, 64, kernel_size = 3, stride = 2, padding = 1)\n",
    "            , nn.BatchNorm2d(64)\n",
    "            , nn.ReLU()\n",
    "            , nn.Conv2d(64, 128, kernel_size = 3, stride = 2, padding = 1)\n",
    "            , nn.BatchNorm2d(128)\n",
    "            , nn.ReLU()\n",
    "            , nn.AdaptiveAvgPool2d(1)\n",
    "            , nn.Flatten()\n",
    "            , nn.Linear(128, 512)\n",
    "            , nn.ReLU()\n",
    "            , nn.Dropout()\n",
    "            , nn.Linear(512, 64)\n",
    "            , nn.ReLU()\n",
    "            , nn.Dropout()\n",
    "            , nn.Linear(64, num_classes)\n",
    "            # , nn.Softmax(dim=-1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  MobileNet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Model_Class_Transfer_Learning_MobileNet.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Model_Class_Transfer_Learning_MobileNet.py\n",
    "\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        weights = models.MobileNet_V2_Weights.IMAGENET1K_V2\n",
    "        self.network = models.mobilenet_v2(weights=weights)\n",
    "        num_ftrs = self.network.classifier[1].in_features\n",
    "        self.network.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.network(x)\n",
    "        # x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile PyTorch_Classification_Training_Class.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "from Model_Class_From_the_Scratch import MODEL_From_Scratch\n",
    "from Model_Class_Transfer_Learning_MobileNet import MobileNet\n",
    "from Dataset_Class import PyTorch_Classification_Dataset_Class as Dataset\n",
    "\n",
    "class PyTorch_Classification_Training_Class():\n",
    "    def __init__(self\n",
    "                 , dataset_dir = os.path.join(os.getcwd(), \"Recycle_Classification_Dataset\")\n",
    "                , batch_size = 16\n",
    "                , train_ratio = 0.75\n",
    "                ):\n",
    "        \n",
    "        if not os.path.isdir(dataset_dir):\n",
    "            os.system(\"git clone https://github.com/JinFree/Recycle_Classification_Dataset.git\")\n",
    "            shutil.rmtree(os.path.join(os.getcwd(), \"Recycle_Classification_Dataset\", \".git\"))\n",
    "        self.USE_CUDA = torch.cuda.is_available()\n",
    "        self.DEVICE = torch.device(\"cuda\" if self.USE_CUDA else \"cpu\")\n",
    "        self.transform = transforms.Compose([\n",
    "                transforms.Resize(256)\n",
    "                , transforms.RandomCrop(224)\n",
    "                , transforms.ToTensor()\n",
    "                , transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        \n",
    "        dataset = Dataset(dataset_dir = dataset_dir, transform = self.transform)\n",
    "        dataset.__save_label_map__()\n",
    "        self.num_classes = dataset.__num_classes__()\n",
    "        train_size = int(train_ratio * len(dataset))\n",
    "        test_size = len(dataset) - train_size\n",
    "        train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(\n",
    "            train_dataset\n",
    "            , batch_size=batch_size\n",
    "            , shuffle=True\n",
    "        )\n",
    "        self.test_loader = torch.utils.data.DataLoader(\n",
    "            test_dataset\n",
    "            , batch_size=batch_size\n",
    "            , shuffle=False\n",
    "        )\n",
    "        self.model = None\n",
    "        self.model_str = None\n",
    "\n",
    "    def prepare_network(self, is_scratch = True):\n",
    "        if is_scratch:\n",
    "            self.model = MODEL_From_Scratch(self.num_classes)\n",
    "            self.model_str = \"PyTorch_Training_From_Scratch\"\n",
    "        else:\n",
    "            self.model = MobileNet(self.num_classes)\n",
    "            self.model_str = \"PyTorch_Transfer_Learning_MobileNet\"\n",
    "        self.model.to(self.DEVICE)\n",
    "        self.model_str += \".pt\"\n",
    "\n",
    "    def training_network(self\n",
    "            , learning_rate = 0.0001\n",
    "            , epochs = 10\n",
    "            , step_size = 3\n",
    "            , gamma = 0.3):\n",
    "        if self.model is None:\n",
    "            self.prepare_network(False)\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "        acc = 0.0\n",
    "\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            print(f\"Use CUDA = {torch.cuda.is_available()}\")\n",
    "            self.model.train()\n",
    "            for data, target in tqdm(self.train_loader):\n",
    "                data, target = data.to(self.DEVICE), target.to(self.DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                output = self.model(data)\n",
    "                loss = F.cross_entropy(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "            self.model.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data, target in tqdm(self.test_loader):\n",
    "                    data, target = data.to(self.DEVICE), target.to(self.DEVICE)\n",
    "                    output = self.model(data)\n",
    "                    test_loss += F.cross_entropy(output, target, reduction='sum').item()\n",
    "                    pred = output.max(1, keepdim=True)[1]\n",
    "                    correct += (pred == target).float().mean().item()\n",
    "\n",
    "            test_loss /= len(self.test_loader.dataset)\n",
    "            test_accuracy = 100. * correct / len(self.test_loader.dataset)\n",
    "            print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, test_loss, test_accuracy))\n",
    "            if acc < test_accuracy:\n",
    "                acc = test_accuracy\n",
    "                torch.save(self.model.state_dict(), self.model_str)\n",
    "                print(\"model saved!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    training_class = PyTorch_Classification_Training_Class()\n",
    "    training_class.prepare_network(True) # Scratch model\n",
    "    # training_class.prepare_network(False) # MobileNet\n",
    "    training_class.training_network(learning_rate = 0.00001, epochs=10, step_size=3, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Inference_Cam.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Inference_Cam.py\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from Model_Class_From_the_Scratch import MODEL_From_Scratch\n",
    "from Model_Class_Transfer_Learning_MobileNet import MobileNet\n",
    "\n",
    "class Inference_Class():\n",
    "    def __init__(self):\n",
    "        USE_CUDA = torch.cuda.is_available()\n",
    "        self.DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "        self.model = None\n",
    "        self.label_map = None\n",
    "        self.transform_info = transforms.Compose(\n",
    "                [\n",
    "                transforms.Resize(size=(224, 224)),\n",
    "                transforms.ToTensor()\n",
    "                ])\n",
    "        \n",
    "    def load_model(self, is_train_from_scratch, label_map_file = \"label_map.txt\"):\n",
    "        self.label_map = np.loadtxt(label_map_file, str, delimiter='\\t')\n",
    "        num_classes = len(self.label_map)\n",
    "        model_str = None\n",
    "        if is_train_from_scratch:\n",
    "            self.model = MODEL_From_Scratch(num_classes).to(self.DEVICE)\n",
    "            model_str = \"PyTorch_Training_From_Scratch\"\n",
    "        else:\n",
    "            self.model = MobileNet(num_classes).to(self.DEVICE)\n",
    "            model_str = \"PyTorch_Transfer_Learning_MobileNet\"\n",
    "        model_str += \".pt\"\n",
    "        self.model.load_state_dict(torch.load(model_str, map_location=self.DEVICE))\n",
    "        self.model.eval()\n",
    "\n",
    "    def inference_video(self, video_source=\"test_video.mp4\"):\n",
    "        cap = cv2.VideoCapture(video_source)\n",
    "        if cap.isOpened():\n",
    "            print(\"Video Opened\")\n",
    "        else:\n",
    "            print(\"Video Not Opened\")\n",
    "            print(\"Program Abort\")\n",
    "            exit()\n",
    "        cv2.namedWindow(\"Output\", cv2.WINDOW_GUI_EXPANDED)\n",
    "        with torch.no_grad():\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    output = self.inference_frame(frame)\n",
    "                    cv2.imshow(\"Output\", output)\n",
    "                else:\n",
    "                    break\n",
    "                if cv2.waitKey(33) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "        return\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"-s\", \"--is_scratch\",\n",
    "#             required=False,\n",
    "#             action=\"store_true\",\n",
    "#             help=\"inference with model trained from the scratch\")\n",
    "#     parser.add_argument(\"-src\", \"--source\",\n",
    "#             required=False,\n",
    "#             type=str,\n",
    "#             default=\"./test_video.mp4\",\n",
    "#             help=\"OpenCV Video source\")\n",
    "#     args = parser.parse_args()\n",
    "#     is_train_from_scratch = False\n",
    "#     source = args.source\n",
    "#     if args.is_scratch:\n",
    "#         is_train_from_scratch = True\n",
    "#     inferenceClass = Inference_Class()\n",
    "#     inferenceClass.load_model(is_train_from_scratch)\n",
    "#     inferenceClass.inference_video(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추론 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Inference_Cam import Inference_Class\n",
    "\n",
    "# 클래스를 초기화하고 모델을 불러옵니다.\n",
    "inferenceClass = Inference_Class()\n",
    "is_train_from_scratch = False\n",
    "inferenceClass.load_model(is_train_from_scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "\n",
    "def inference(input_image):\n",
    "    cv_image = []\n",
    "    if isinstance(input_image, str):\n",
    "        cv_image = cv2.imread(input_image, cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        cv_image = np.copy(input_image)\n",
    "    result_frame, label_text, class_prob = inferenceClass.inference_image(cv_image)\n",
    "    print(\"입력 이미지는 {} % 확률로 {}으로 분류됩니다.\".format((float)(class_prob) * 100, label_text))\n",
    "    cv2_imshow(result_frame)\n",
    "\n",
    "    return result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = os.path.join(os.getcwd(), \"test_image_1.jpg\")\n",
    "result = inference(input_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_lecture",
   "language": "python",
   "name": "ml_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_seed(seed=123, deter=False):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = deter\n",
    "    torch.use_deterministic_algorithms = deter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7388, 0.7179],\n",
      "         [0.7058, 0.9156],\n",
      "         [0.4340, 0.0772],\n",
      "         [0.3565, 0.1479],\n",
      "         [0.5331, 0.4066]]])\n",
      "torch.Size([1, 5, 2])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "input_size = 2\n",
    "hidden_size = 4\n",
    "\n",
    "inputs = torch.rand((1, 5, input_size))\n",
    "\n",
    "print(inputs)\n",
    "print(inputs.shape)\n",
    "print(inputs.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.2682, -0.0455],\n",
      "        [ 0.4737, -0.0394],\n",
      "        [ 0.0159, -0.0780],\n",
      "        [ 0.0786,  0.4455]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3057,  0.1775,  0.1087,  0.1179],\n",
      "        [ 0.1932, -0.0646, -0.4647, -0.3092],\n",
      "        [ 0.4268,  0.0299, -0.4050,  0.0789],\n",
      "        [ 0.4131, -0.4725, -0.3366, -0.1991]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0201, -0.1166, -0.0549, -0.4874], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.2341,  0.4389,  0.3056, -0.3541], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "torch_seed()\n",
    "\n",
    "print(list(rnn.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0234,  0.5675,  0.2035, -0.4330],\n",
      "         [ 0.1019,  0.5564,  0.1005, -0.5503],\n",
      "         [ 0.2072,  0.5594,  0.2237, -0.7250],\n",
      "         [ 0.2481,  0.5437,  0.1995, -0.6948],\n",
      "         [ 0.2020,  0.6003,  0.2107, -0.6054]]], grad_fn=<TransposeBackward1>)\n",
      "tensor([[[ 0.2020,  0.6003,  0.2107, -0.6054]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs, _status = rnn(inputs)\n",
    "print(outputs)\n",
    "print(_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0506, -0.3345, -0.0627, -0.4197,  0.3749,  0.3338],\n",
      "         [-0.2343, -0.1329,  0.1991, -0.2963,  0.4662,  0.1552],\n",
      "         [-0.1321, -0.2785,  0.2445, -0.3711,  0.6102,  0.1623],\n",
      "         [-0.0717, -0.2599,  0.3451, -0.3760,  0.6385,  0.1538],\n",
      "         [-0.0166, -0.2569,  0.3646, -0.3898,  0.6689,  0.1642]]],\n",
      "       grad_fn=<TransposeBackward1>)\n",
      "tensor([[[ 0.1740, -0.2262,  0.0954,  0.4356,  0.1677, -0.2853]],\n",
      "\n",
      "        [[-0.0166, -0.2569,  0.3646, -0.3898,  0.6689,  0.1642]]],\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[ 0.1740, -0.2262,  0.0954,  0.4356,  0.1677, -0.2853]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[-0.0166, -0.2569,  0.3646, -0.3898,  0.6689,  0.1642]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.Tensor(1, 5, 2)\n",
    "cell = nn.RNN(input_size=2, hidden_size=6, num_layers=2, batch_first=True)\n",
    "\n",
    "outputs, _status = cell(inputs)\n",
    "print(outputs)\n",
    "print(_status)\n",
    "\n",
    "print(_status[0])\n",
    "print(_status[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = 'apple'\n",
    "label_str = 'pple!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', 'a', 'e', 'l', 'p']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(input_str+label_str)))\n",
    "vocab_size = len(char_vocab)\n",
    "print(char_vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, 'a': 1, 'e': 2, 'l': 3, 'p': 4}\n",
      "{0: '!', 1: 'a', 2: 'e', 3: 'l', 4: 'p'}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
    "print(char_to_index)\n",
    "\n",
    "index_to_char = dict((i, c) for i, c in enumerate(char_vocab))\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 4, 3, 2]\n",
      "[4, 4, 3, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "x_data = [char_to_index[c] for c in input_str]\n",
    "y_data = [char_to_index[c] for c in label_str]\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 4, 4, 3, 2]]\n",
      "[[4, 4, 3, 2, 0]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [x_data]\n",
    "y_data = [y_data]\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = np.eye(vocab_size)[x_data]\n",
    "\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "torch.Size([1, 5])\n",
      "tensor([[[0., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.]]])\n",
      "tensor([[4, 4, 3, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = vocab_size\n",
    "hidden_size = 6\n",
    "output_size = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VanillaRNN(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n",
      "tensor([[[ 0.6672, -0.4526,  0.0573, -0.2197,  0.4151],\n",
      "         [ 0.4566, -0.4126, -0.1461, -0.2106,  0.1750],\n",
      "         [ 0.3333, -0.4490, -0.1274, -0.1861,  0.2743],\n",
      "         [ 0.7592, -0.4006, -0.0284, -0.1635,  0.2178],\n",
      "         [ 0.5743, -0.4294, -0.0412, -0.3804,  0.3693]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(X)\n",
    "print(outputs.shape)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6672, -0.4526,  0.0573, -0.2197,  0.4151],\n",
      "         [ 0.4566, -0.4126, -0.1461, -0.2106,  0.1750],\n",
      "         [ 0.3333, -0.4490, -0.1274, -0.1861,  0.2743],\n",
      "         [ 0.7592, -0.4006, -0.0284, -0.1635,  0.2178],\n",
      "         [ 0.5743, -0.4294, -0.0412, -0.3804,  0.3693]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[4, 4, 3, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6672, -0.4526,  0.0573, -0.2197,  0.4151],\n",
      "        [ 0.4566, -0.4126, -0.1461, -0.2106,  0.1750],\n",
      "        [ 0.3333, -0.4490, -0.1274, -0.1861,  0.2743],\n",
      "        [ 0.7592, -0.4006, -0.0284, -0.1635,  0.2178],\n",
      "        [ 0.5743, -0.4294, -0.0412, -0.3804,  0.3693]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([4, 4, 3, 2, 0])\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(outputs.view(-1, output_size))\n",
    "print(Y.view(-1))\n",
    "\n",
    "print(outputs.argmax(axis=2).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 loss: 1.513 prediction: tensor([[0, 0, 0, 0, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: !!!!!\n",
      "1 loss: 1.239 prediction: tensor([[4, 4, 3, 3, 4]]) true Y: [[4, 4, 3, 2, 0]] prediction str: ppllp\n",
      "2 loss: 0.96 prediction: tensor([[4, 4, 3, 2, 4]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pplep\n",
      "3 loss: 0.69 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "4 loss: 0.465 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "5 loss: 0.302 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "6 loss: 0.202 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "7 loss: 0.13 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "8 loss: 0.086 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "9 loss: 0.057 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "10 loss: 0.038 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "11 loss: 0.027 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "12 loss: 0.02 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "13 loss: 0.014 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "14 loss: 0.01 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "15 loss: 0.008 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "16 loss: 0.006 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "17 loss: 0.005 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "18 loss: 0.004 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "19 loss: 0.003 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "20 loss: 0.003 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "21 loss: 0.002 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "22 loss: 0.002 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "23 loss: 0.002 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "24 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "25 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "26 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "27 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "28 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "29 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "30 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "31 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "32 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "33 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "34 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "35 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "36 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "37 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "38 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "39 loss: 0.001 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "40 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "41 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "42 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "43 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "44 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "45 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "46 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "47 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "48 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "49 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "50 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "51 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "52 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "53 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "54 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "55 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "56 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "57 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "58 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "59 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "60 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "61 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "62 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "63 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "64 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "65 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "66 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "67 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "68 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "69 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "70 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "71 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "72 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "73 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "74 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "75 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "76 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "77 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "78 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "79 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "80 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "81 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "82 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "83 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "84 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "85 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "86 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "87 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "88 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "89 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "90 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "91 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "92 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "93 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "94 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "95 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "96 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "97 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "98 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n",
      "99 loss: 0.0 prediction: tensor([[4, 4, 3, 2, 0]]) true Y: [[4, 4, 3, 2, 0]] prediction str: pple!\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(100):\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs.view(-1, output_size), Y.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.argmax(axis=2)\n",
    "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result).numpy()])\n",
    "    print(i, \"loss:\", round(loss.item(), 3), \"prediction:\", result, 'true Y:', y_data, \"prediction str:\", result_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글을 이용한 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요 여러분\n",
      "녕하세요 여러분!\n"
     ]
    }
   ],
   "source": [
    "text = '안녕하세요 여러분'\n",
    "input_str_kr = text\n",
    "label_str_kr = text[1:] +'!'\n",
    "\n",
    "print(input_str_kr)\n",
    "print(label_str_kr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'러', '하', '!', '녕', ' ', '분', '여', '세', '요', '안'}\n",
      "[' ', '!', '녕', '러', '분', '세', '안', '여', '요', '하']\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "voc_set = set(input_str_kr+label_str_kr)\n",
    "char_vocab = sorted(list(voc_set))\n",
    "vocab_size = len(char_vocab)\n",
    "\n",
    "print(voc_set)\n",
    "print(char_vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '녕': 2, '러': 3, '분': 4, '세': 5, '안': 6, '여': 7, '요': 8, '하': 9}\n",
      "{0: ' ', 1: '!', 2: '녕', 3: '러', 4: '분', 5: '세', 6: '안', 7: '여', 8: '요', 9: '하'}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
    "print(char_to_index)\n",
    "\n",
    "index_to_char = dict((i, c) for i, c in enumerate(char_vocab))\n",
    "print(index_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 2, 9, 5, 8, 0, 7, 3, 4]]\n",
      "[[2, 9, 5, 8, 0, 7, 3, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "x_data = [[char_to_index[c] for c in input_str_kr]]\n",
    "y_data = [[char_to_index[c] for c in label_str_kr]]\n",
    "\n",
    "print(x_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "x_one_hot = np.eye(vocab_size)[x_data]\n",
    "\n",
    "print(x_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]])\n",
      "tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]])\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor(x_one_hot)\n",
    "Y = torch.LongTensor(y_data)\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of VanillaRNN_Kor(\n",
      "  (rnn): RNN(10, 20, batch_first=True)\n",
      "  (fc): Linear(in_features=20, out_features=10, bias=True)\n",
      ")>\n",
      "0 loss: 2.327 prediction: tensor([[9, 9, 8, 9, 6, 9, 9, 9, 9]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 하하요하안하하하하\n",
      "1 loss: 1.8 prediction: tensor([[2, 9, 5, 9, 0, 9, 3, 2, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세하 하러녕!\n",
      "2 loss: 1.074 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 5, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러세!\n",
      "3 loss: 0.446 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "4 loss: 0.163 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "5 loss: 0.055 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "6 loss: 0.02 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "7 loss: 0.008 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "8 loss: 0.004 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "9 loss: 0.002 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "10 loss: 0.001 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "11 loss: 0.001 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "12 loss: 0.001 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "13 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "14 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "15 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "16 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "17 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "18 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "19 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "20 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "21 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "22 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "23 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "24 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "25 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "26 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "27 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "28 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "29 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "30 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "31 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "32 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "33 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "34 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "35 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "36 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "37 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "38 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "39 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "40 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "41 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "42 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "43 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "44 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "45 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "46 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "47 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "48 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "49 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "50 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "51 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "52 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "53 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "54 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "55 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "56 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "57 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "58 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "59 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "60 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "61 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "62 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "63 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "64 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "65 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "66 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "67 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "68 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "69 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "70 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "71 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "72 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "73 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "74 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "75 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "76 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "77 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "78 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "79 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "80 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "81 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "82 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "83 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "84 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "85 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "86 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "87 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "88 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "89 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "90 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "91 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "92 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "93 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "94 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "95 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "96 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "97 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "98 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n",
      "99 loss: 0.0 prediction: tensor([[2, 9, 5, 8, 0, 7, 3, 4, 1]]) true Y: [[2, 9, 5, 8, 0, 7, 3, 4, 1]] prediction str: 녕하세요 여러분!\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(char_vocab)\n",
    "input_size = vocab_size\n",
    "hidden_size = 20\n",
    "output_size = vocab_size\n",
    "learning_rate = 0.1\n",
    "\n",
    "class VanillaRNN_Kor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x , _status = self.rnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "net = VanillaRNN_Kor(input_size, hidden_size, output_size)\n",
    "print(net.parameters)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "for i in range(100):\n",
    "    outputs = net(X)\n",
    "    loss = criterion(outputs.view(-1, output_size), Y.view(-1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    result = outputs.argmax(axis=2)\n",
    "    result_str = ''.join([index_to_char[c] for c in np.squeeze(result).numpy()])\n",
    "    print(i, \"loss:\", round(loss.item(), 3), \"prediction:\", result, 'true Y:', y_data, \"prediction str:\", result_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM을 이용한 영화 리뷰 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7200, 0.8107, 0.0901, 0.3766, 0.2162],\n",
      "         [0.2487, 0.4383, 0.6422, 0.2299, 0.3147],\n",
      "         [0.5300, 0.8756, 0.4635, 0.6490, 0.7249]]])\n",
      "torch.float32\n",
      "torch.Size([1, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib import request\n",
    "\n",
    "input_dim = 5\n",
    "hidden_size = 3\n",
    "\n",
    "inputs = torch.rand(1, 3, 5)\n",
    "print(inputs)\n",
    "print(inputs.dtype)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.2246,  0.5499, -0.1073, -0.1129, -0.1378],\n",
      "        [ 0.5190,  0.2085, -0.3787, -0.0854, -0.1555],\n",
      "        [-0.0650,  0.4903, -0.2045,  0.0726, -0.4082],\n",
      "        [-0.5200, -0.2374,  0.0030,  0.1109, -0.3820],\n",
      "        [ 0.5747,  0.4850, -0.2531, -0.1494,  0.4621],\n",
      "        [-0.5327, -0.4004,  0.5042,  0.5536,  0.4995],\n",
      "        [ 0.4724,  0.4621,  0.0836, -0.0287, -0.0046],\n",
      "        [-0.5560, -0.2912, -0.0042, -0.2184,  0.4152],\n",
      "        [-0.2537,  0.1111, -0.2759,  0.3105, -0.5026],\n",
      "        [ 0.2394,  0.5469, -0.2024,  0.5086,  0.0399],\n",
      "        [-0.4681, -0.5723,  0.2233,  0.2187, -0.3615],\n",
      "        [ 0.3662,  0.2126, -0.4324, -0.1043, -0.3270]], requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.3815, -0.1068,  0.5448],\n",
      "        [ 0.0606,  0.3318,  0.4958],\n",
      "        [-0.0583, -0.1228,  0.1885],\n",
      "        [ 0.0096,  0.4449, -0.0524],\n",
      "        [ 0.5760,  0.3786,  0.4486],\n",
      "        [-0.0960, -0.0086,  0.4365],\n",
      "        [-0.1709,  0.4585,  0.0352],\n",
      "        [ 0.2276,  0.4801,  0.4301],\n",
      "        [-0.4132,  0.5006,  0.3826],\n",
      "        [-0.5754,  0.4153,  0.1674],\n",
      "        [ 0.1284, -0.4965, -0.1341],\n",
      "        [ 0.3308,  0.0829,  0.3136]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4428,  0.3774,  0.1113,  0.3153,  0.4839,  0.3663,  0.0410,  0.1543,\n",
      "         0.3638, -0.0384, -0.2628,  0.3686], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0776, -0.0554, -0.5573, -0.1483,  0.5761, -0.0842,  0.1475,  0.2745,\n",
      "        -0.2981,  0.4722,  0.5305, -0.0965], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
    "print(list(lstm.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x241e1929d30>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", \n",
    "                    filename=\"ratings_train.txt\")\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", \n",
    "                    filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('ratings_train.txt', sep = \"\\t\", nrows = 10000)\n",
    "test_data = pd.read_table('ratings_test.txt', sep = \"\\t\", nrows = 10000)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9918\n"
     ]
    }
   ],
   "source": [
    "train_data.dropna(inplace=True, how='any')\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙   진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼   솔직히 재미는 없다  평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀  세부터 초등학교  학년생인  살용영화 ㅋㅋㅋ   별반개도 아까움</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지  정말 발로해도 그것보단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데  꽤 볼만한데   헐리우드식 화려함에만 너무 길들여져 있나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙   진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼   솔직히 재미는 없다  평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "5   5403919      막 걸음마 뗀  세부터 초등학교  학년생인  살용영화 ㅋㅋㅋ   별반개도 아까움       0\n",
       "6   7797314                              원작의 긴장감을 제대로 살려내지못했다       0\n",
       "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지  정말 발로해도 그것보단...      0\n",
       "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
       "9   5912145      왜케 평점이 낮은건데  꽤 볼만한데   헐리우드식 화려함에만 너무 길들여져 있나       1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \", regex=True)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n",
      "(9858, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙   진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼   솔직히 재미는 없다  평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5403919</td>\n",
       "      <td>막 걸음마 뗀  세부터 초등학교  학년생인  살용영화 ㅋㅋㅋ   별반개도 아까움</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7797314</td>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9443947</td>\n",
       "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지  정말 발로해도 그것보단...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7156791</td>\n",
       "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5912145</td>\n",
       "      <td>왜케 평점이 낮은건데  꽤 볼만한데   헐리우드식 화려함에만 너무 길들여져 있나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙   진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠   포스터보고 초딩영화줄    오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼   솔직히 재미는 없다  평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화 스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "5   5403919       막 걸음마 뗀  세부터 초등학교  학년생인  살용영화 ㅋㅋㅋ   별반개도 아까움      0\n",
       "6   7797314                               원작의 긴장감을 제대로 살려내지못했다      0\n",
       "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지  정말 발로해도 그것보단...      0\n",
       "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
       "9   5912145       왜케 평점이 낮은건데  꽤 볼만한데   헐리우드식 화려함에만 너무 길들여져 있나      1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.strip()\n",
    "train_data['document'] = train_data['document'].replace('', np.nan)\n",
    "train_data.dropna(how='any', inplace=True)\n",
    "print(train_data.isnull().sum())\n",
    "print(train_data.shape)\n",
    "train_data.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_lecture",
   "language": "python",
   "name": "ml_lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
